In this paper we give a purely functional implementation of LR-parsers , applicable to general CF grammars . It will be obtained as a generalization of the well-known recursive descent parsing technique . For LR ( 0 ) grammars , our result implies a deterministic parser that is closely related to the recursive ascent parsers discovered by Kruseman Aretz [ 1 ] and Roberts [ 2 ] . In the general non-deterministic case , the parser has cubic time complexity if the parse functions are implemented as memo-functions [ 3 ] , which are functions that memorize and re-use the results of previous invocations . Memofunctions are easily implemented in most programming languages . The notion of memo-functions is also used to define an algorithm that constructs a cubic representation for the parse forest , i.e . the collection of parse trees . It has been claimed by Tomita that non-deterministic LR-parsers are useful for natural language processing . In [ 4 ] he presented a discussion about how to do nondeterministic LR-parsing , with a device called a graphstructured stack . With our parser we show that no explicit stack manipulations are needed ; they can be expressed implicitly with the use of appropriate programming language concepts . Most textbooks on parsing do not include proper correctness proofs for LR-parsers , mainly because such proofs tend to be rather involved . The theory of LRparsing should still be considered underdeveloped , for this reason . Our presentation , however , contains a surprisingly simple correctness proof . In fact , this proof is this paper 's major contribution to parsing theory . One of its lessons is that the CF grammar class is often the natural one to proof parsers for , even if these parsers are devoted to some special class of grammars . If the grammarlis restricted in some way , a parser for general CF grammars may have properties that enable smart implementation tricks to enhance efficiency . As we show below , the relation between LR-parsers and LR-grammars is of this kind . Especially in natural language processing , standard CF grammars are often too limited in their strong generative power . The extended CF grammar formalism , allowing rules to have regular expressions at the right hand side , is a useful extension , for that reason . It is not difficult to generalize our parser to cope with extended grammars , although the application of LR-parsing to extended CF grammars is well-known to be problematic [ 5 ] . We first present the recursive descent recognizer in a way that allows the desired generalization . Then we obtain the recursive ascent recognizer and its proof . If the grammar is LR ( 0 ) a few implementation tricks lead to the recursive ascent recognizer of ref . [ 1 ] . Subsequently , the time and space complexities of the recognizer are analysed , and the algorithm for constructing a cubic representation for parse forests is given . The paper ends with a discussion of extended CF grammars . Consider CF grammar G , with terminals VT and nonterminals V/v . Let V = VN U VT. A well-known topdown parsing technique is the recursive descent parser . Recursive descent parsers consist of a number of procedures , usually one for each non-terminal . Here we present a variant that consists of functions , one for each item ( dotted rule ) . We use the unorthodox embracing operator [ . ] to map each item to its function : ( we use greek letters for arbitrary elements of V * ) with B E V , and 1/31 the number of symbols in 3 ( with H = 0 ) . A recursive ascent recognizer may be obtained by relating to each state q not only the above [ q ] , but also a function__ that we take to be the result of applying operator [ . ] to the state : The set $ 1 may be rewritten using the specification of [ q ] ( C , k ) : ini ( q ) = { B -- * .AIB - . A ^ A -- * a.3 • q A 3 =¢ B-r } . [ q ] : V x N -- * 2 I° A ( l , j ) E-~ ( B , i ) } U { ( l , i ) lI • q ^ final ( l ) } [ q ] ( B , i ) = { ( pop ( l ) , J ) l ( 1 , j ) • [ ooto ( q , B ) ] ( i ) ^ pop ( l ) • q } U { ( I,4 ) 1 ( J , k ) • [ goto ( q , B ) I~^ pop ( J ) • ini ( q ) ^ ( 1 , j ) • [ q ] ( lhs ( S ) , k ) } Proof : First we notice that /8 `` * * xi+l .. -xj 3~ ( 3 ~ * zi+l't ^ 7 ~ '' z , +2 ... zj ) v 3B~ ( 3 ~ '' B-r ^ B ~ c ^ -y -- . '' z , +~ ... zj ) v ( ~=~^i=j ) Hence [ q ] ( i ) = { ( A -- * a.3 , J ) l ( A -- * a.3 , j ) • r~ ( z , +~ , i+ 1 ) } u { ( A -- , , ~.3 , J ) l B -.- . eA ( A -- , a.3 , j ) • [ q ] ( B , i ) } u { ( A -- ~ a. , i ) la -- * a . • q } S1 : { ( A -'~ a.~ , j ) l ( A -~ a.~ , j ) E [ q ] ( C , k ) A C -- * B6 A 6 -- , '' xi+ , ... xk } . Also , as before , ~ =~ * C ' r implies that all items C ~ .g are in ini ( q ) , and the existence of C - * .B~ in ini ( q ) implies C ~ B.~ E goto ( q , B ) : Sx = { ( A ~ a.~ , j ) l ( A ~ ~.B , j ) E [ q ] ( C , k ) A C -- ~ .B~ E ini ( q ) A ( C -- . B.6 , k ) ~ [ goto ( q , B ) ] ( i ) } . n In the computation of [ q0 ] ( 0 ) , functions are needed only for states in the canonical collection of LR ( 0 ) states [ 6 ] for G , i.e . for every state that can be reached from the initial state by repeated application of the goto function . Note that in general the state ¢ will be among these , and that both [ ¢ ] ( i ) and [ g ] ( B , i ) are empty sets for all i _ > 0 and B E V . One can prove that , if the grammar is LR ( 0 ) , each recognizer function for a canonical LR ( 0 ) state results in a set with at most one element . The functions for nonempty q may in this case be rephrased as Therefore , R can be replaced by two variables X E V and an integer I , making the following substitutions in the previous procedures : R : =A -- * a . =~ X : =A ; I : =Icrl R : =pop ( R ) =~ l : = l-1 pop ( R ) E q =~ l # l v X = S ' lhs ( R ) =~ X After these substitutions , one gets close to the recursive ascent recognizer as it was presented in [ 1 ] . A recognizer that is virtually the same as in [ l~s obtained by replacing the tail-recursive procedure [ q ] by an iterative loop . Then one is left with one procedure for each state . While parsing there is , at each instance , a stack of activated procedures that corresponds to the stacks that are explicitly maintained in conventional implementations of deterministic LR-parsers . For LL ( 0 ) grammars the recursive descent recognizer is deterministic and works in linear time . The same is true of the ascent recognizer for LR ( 0 ) grammars . In the general , non-deterministic , case the recursive descent and ascent recognizers need exponential time unless the functions are implemented as memo-functions [ 3 ] . Memo-functions memorize for which arguments they have been called . If a function is called with the same arguments as before , the function returns the previous result without recomputing it . In conventional programming languages memo-functions are not available , but they can easily be implemented . Devices like graphstructured stacks [ 4 ] , parse matrices [ 7 ] , or welbformed substring tables [ 8 ] , are in fact low-level realizations of the abstract notion of memo-functions . The complexity analysis of the recognizers is quite simple . for the whole recognizer . The above considerations only hold if the parser terminates . The recursive descent parser terminates for all grammars that are not left-recursive . For the recursive ascent parser , the situation is more complicated . If the gra_m.mmar has a cyclic derivation B - * * B , the execution of The space required for a parser that also calculates a parse forest , is dominated by this forest . We show in the next section that it may be compressed into a cubic amount of space . In the complexity domain our ascent parser beats its rival , Tomita 's parsing method [ 4 ] , which is non-polynomial : for each integer k there exists a grammar such that the complexity of the Tomita parser is worse than n k . In addition to the complexity as a function of sentence length , one may also consider the complexity as a function of grammar size . It is clear that both time and space complexity are proportional to the number of parsing procedures . The number of procedures of the recursive descent parser is proportional to the number of items , and hence a linear function of the grammar size . The recursive ascent parser , however , contains two functions for each LR-state and is hence proportional to the size of the canonical collection of LR ( 0 ) states . In the worst case , this size is an exponential function of grammar size , but in the average natural language case there seems to be a linear , or even sublinear , dependence Usually , the recognition process is followed by the construction of parse trees . For ambiguous grammars , it becomes an issue how to represent the set of parse trees as compactly as possible . Below , we describe how to obtain a cubic representation in cubic time . We do so in three steps . In the first step , we observe that ambiguity often arises locally : given a certain context C Of course , this idea should be applied recursively . Technically , this leads to a kind of tree-llke structure in which each child is a set of substructures rather than a single one . The sharing of context can be carried one step further . If we have , in one and the same context , a number of applied occurrences of a production rule A -- - , a/~ which share also the same parse forest for a , we can represent the context of A -- - * a~ itself and the common parse forest for a only once and fit the set of parse forests for fl into that . Again this idea has to be applied recursively . Technically , this leads to a binary representation of parse trees , with each node having at most two sons , and to the application of the context sharing technique to this binary representation . These The representation for the set of parse trees is then just f ( S , 0 , n ) . We now come to our third step . Suppose , for the mo- An extended CF grammar consists of grammar rules with regular expressions at the right hand side . Every extended CF grammar can be translated into a normal CF grammar by replacing each right hand side by a regular ( sub ) grammar . The strong generative power is different from CF grammars , however , as the degree of the nodes in a derivation tree is unbounded . To apply our recognizer directly to extended grammars , a few of the foregoing definitiovs have to be revised . As before , a grammar rule is written A -- , a , but with a now a regular expression with Na symbols ( elements of V ) . Defining T + = 1 ... N , , and Ta = 0 ... Na , regular expression tr can be characterized by goto ( q , B ) = { ( a -- - , a , k ) i.e . every state has at most one final item , and in case it has a final item it has no items ( A -- , ~ , j ) with k e succ , ~ ( j ) A ~b , ~ ( k ) • VT. 2. for all reachable states q , q N ini ( q ) = ~ , and for all I there is at most one J • ~ such that J E pop ( I ) . In the deterministic case , the analysis of section 4 can be repeated with one exception : extended grammar items can not be represented by a non-terminal and an integer that equals the number of symbols before thc dot , as this notion is irrelevant in the case of regular expressions . In standard presentations of deterministic LR-parsing this leads to almost unsurmountable problems [ 5 ] . We established a very simple and elegant implementation of LR ( 0 ) parsing . It is easily extended to LALR ( k ) parsing by letting the functions [ q ] produce pairs with final items only after inspection of the next k input symbols . The functional LR-parser provides a high-level view of LR-parsing , compared to conventional implementations . A case in point is the ubiquitous stack , that simply corresponds to the procedure stack in the functional case . As the proof of a functional LR-parser is not hindered by unnecessary implementation details , it can be very compact . Nevertheless , the functional implementation is as efficient as conventional ones . Also , the notion of memo-functions is an important primitive for presenting algorithms at a level of abstraction that can not be achieved without them , as is exemplified by this paper 's presentation of both the recognizers and the parse forests . For non-LR grammars , there is no reason to use the complicated Tomita algorithm . If indeed nondeterministic LR-parsers beat the Earley algorithm for some natural language grammars , as claimed in [ 4 ] , this is because the number of LR ( 0 ) states may be smaller than the size of IG for such grammars . Evidently , for the grammars examined in [ 4 ] this advantage compensates the loss of efficiency caused by the non-polynomiality of Tomita 's algorithm . The present algorithm seems to have the possible advantage of Tomita 's parser , while being polynomial . 