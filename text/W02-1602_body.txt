Creating and maintaining aligned multilingual documents is a growing necessity . In the current practice , a multilingual document consists in many parallel monolingual files , which may be technical documentation as well as help files , message files , or simply thematic information put on the web and intended for a multilingual audience ( medicine , cooking , travel… ) . The task is difficult even for a document managed in a centralized manner . Ususally , it is first created in a unique source language , and translated into several target languages . There must be a way to keep trak of modifications , possibly done at various places on different linguistic versions . From time to time , somebody has to decide which modifications to integrate in the next release of the document . For that , modifications done in target languages have to be translated back into the source language . The new and the old source versions are then compared using ( fuzzy ) matching techniques , so that only really new segments are sent for translation . The problem arises even more if the documents are not managed centrally , so that the monolingual files are often in various formats ( Word , EgWord , Interleaf , FileMaker , DBMS formats , etc . ) . A. Assimi [ 1 , 2 ] has shown how to `` realign '' parallel decentralized documents and apply the methodology sketched above . However , in both cases , human translators have to retranslate the modified or new source segments , or to revise them if they are retranslated by a quality MT system . Contrary to what is often said , quality MT exists , but for specific contexts only . ( See [ 14 ] ) . What we would like to do is to make it possible to share the revision work across languages , whatever the domain and the context . It is clearly impossible to reflect changes on a file in language L0 into files in L1 , … Ln automatically and faithfully , without any intermediate structure to bridge the gap , because that would necessitate at least a perfect fine-grained aligner in case of changing articles or common nouns ( provided the gender and number stay the ame in each Li version ) . In case of replacing a verb by another with a different valency frame in a target Li , the sentence in Li would have to be reanalyzed , transformed accordingly , and regenerated without introducing any new error or imprecision , thereby keeping the manual improvements coming from previous manual revisions . Or we would need a more than perfect MT system , namely one which would be able to analyze the changed utterance in L0 , and to transfer and generate it into a sentence of Li as close as possible as the previous sentence in Li , which again could have been improved manually before . The best and simplest way to go seems to use some formalized interlingua IL and to ( 1 ) reflect the modifications from L0 to the IL , ( 2 ) regenerate into L1 , … Ln from the IL . We should also allow for direct manual improvements , considering that the IL form will not always be present , or not always improvable enough for lack of expressivity , or that generators will never be perfect . We choose UNL [ 3 , 4 , 10 , 11 ] as our IL of choice for various reasons : ( 1 ) it is specifically designed for linguistic and semantic machine processing , ( 2 ) it derives with many improvements from H.Uchida 's pivot used in ATLAS-II ( Fujitsu ) [ 13 ] , still evaluated as the best quality MT system for English-Japanese , with a large coverage ( 586,000 lexical entries in each language ) , ( 3 ) participants of the UNL project1 have built `` deconverters '' from UNL into about 12 languages , and at least the Arabic , Indonesian , Italian , French , Russian , Spanish , and Thai 1 http : //unl.ias.unu.edu deconverters were accessible for experimentation through a web interface at the time of writing , ( 4 ) although formal , UNL graphs ( see below ) are quite easy to understand with little training and may be presented in a `` localized '' way to naive users by translating UNL symbols ( semantic relations , attributes ) and lexemes ( UWs ) into symbols and lexemes of their language , ( 5 ) the UNL project has defined a format embedded in html for files containing a complete multilingual document aligned at the level of utterances , and produced a `` visualizer '' transforming a UNL file into as many html files as languages , and sending them to any web browser . The UNL representation of a text is a list of `` semantic graphs '' , each expressing the meaning of a natural language utterance . Nodes contain lexical units and attributes , arcs bear semantic relations . Connex subgraphs may be defined as `` scopes '' , so that a UNL graph may be a hypergraph . The lexical units , called Universal Words ( UW ) , represent ( sets of ) word meanings , something less ambitious than concepts . Their denotations are built to be intuitively understood by developers knowing English , that is , by all developers in NLP . AUW is an English term or special symbol ( number… ) possibly completed by semantic restrictions : the UW `` process '' represents all word meanings of that lemma , seen as citation form ( verb or noun here ) , and `` process ( icl > do , agt > person ) '' covers only the meanings of processing , working on , etc . The attributes are the ( semantic ) number , genre , time , aspect , modality , etc. , and the 40 or so semantic relations are traditional `` deep cases '' such as agent , ( deep ) object , location , goal , time , etc . One way of looking at a UNL graph corresponding to an utterance in language L is to say that it represents the abstract structure of an equivalent English utterance `` seen from L '' , that is , where semantic attributes not necessarily expressed in L may be absent ( e.g. , aspect coming from French , determination or number from Japanese , etc. ) . We will first present scenarios of increasing internal complexity for the situation where somebody reads a UNL document in her language , corrects it , and wants the corrections to carry over to the corresponding fragment in other languages . We will then study more precisely the correspondence between a text in language L0 and its representation in UNL , and show the advantage of breaking it into 3 parts : text ↔ morpho-syntactic lattice or chart ↔ abstract `` UNL-tree '' ↔ UNL graph . Finally , we present the current status of this work : an experimentation web site , a method to establish the second part of the correspondence , and related research . Suppose a collection of multilingual documents is stored on a server as multilingual files in UNL-html format , or in any other form , e.g . in a data base , provided ( 1 ) it is possible to easily produce the version in any language contained in the document , The French versions have been produced automatically , the German and Chinese manually . The output of the UNL viewer for French is : < HTML > < HEAD > < TITLE > Example 1 El/UNL < /TITLE > < /HEAD > < BODY > J'ai couru dans le parc hier . Mon chien aboya pour moi . < /BODY > < /HTML > and will probably be displayed by a browser as : Example 1 El/UNL J'ai couru dans le parc hier . Mon chien aboya pour moi . and similarly for all other languages . In all scenarios , the user is reading the text in the normal display , not seing any tags , and wants to make some modification , such as moving `` hier '' after `` couru '' and changing `` pour '' to `` vers '' . Activating some button or menu item , she enters a revision interface . In this first scenario , we do n't suppose that there are UNL graphs associated with the segments . The problem is to transmit and add the user 's modifications to the original form of the multilingual document . That is impossible by editing the html documents displayed , because they have no links to the original form . The UNL-html format predates XML , hence the special tags like [ S ] and { unl } , but we may transform it into an equivalent `` UNL-xml '' format . Then , using DOM and javaScript , it is possible to produce various views : that of a viewer , a bilingual or multilingual editable presentation , and a revision ( coedition ) interface . This is an example from an experiment performed for the `` Forum Barcelona 2004 '' on Spanish , Italian , Russian , French and Hindi . Hindi and Russian are not shown , but Japanese has been added by hand . The XML form is simplified . Correct sentences are produced by the deconverters from correct and complete UNL graphs . We suppose here that the UNL graph has been produced from a Chinese version , and does not countain definiteness and aspectual information . Now all results are wrong wrt articles , and some wrt aspect . < unl : S num= '' 1 '' > ʖ M < unl : org lg= '' cn '' > Ƹ < /unl : org > < unl : unl > < unl : arc > agt ( retrieve ( icl > do ) . @ entry . @ future , city ) < /unl : arc > < unl : arc > tim ( retrieve ( icl > do ) . @ entry . @ future , after ) < /unl : arc > < unl : arc > obj ( after , Forum ) < /unl : arc > < unl : arc > obj ( retrieve ( icl > do ) . @ entry . @ future , zone ( icl > place ) . @ indef ) < /unl : arc > < unl : arc > mod ( zone ( icl > place ) . @ indef , coastal ) < /unl : arc > < /unl : unl > < unl : cn > ʖ M Ƹ < /unl : cn > < unl : el > After a Forum , a city will retrieve a coastal zone. < /unl : el > < unl : es > Ciudad recobrará una zona de costal después Foro . < /unl : es > < unl : fr > Une cité retrouvera une zone côtière après un forum . < /unl : fr > < unl : it > Città ricuperarà une zona costiera dopo Forum . < /unl : it > < unl : jp ₶ₜ̯₼R R , ✔⒝ R⌜ ⍽XR R R῎ῌ > < /unl : jp > < /unl : S > The following interface , designed to be used with sharing , may also be used by a reader knowing several languages , displayed on demand . For example , a native Spanish speaker knowing French and English would put the correct articles ( `` La ciudad '' , `` La cité '' , `` The city '' , etc . ) and the perfective aspect ( `` habra recobrado '' , `` will have recovered '' ) , but a native French speaker would probably not correct the aspect in English a n d S p a n i s h , because aspect is often underspecified in French , e.g . in `` retrouvera '' . Second Deconversion Une cité retrouvera une zone côtière après un forum . La cité retrouvera une zone côtière après le Forum . Une cité retrouvera une zone côtière après un forum . After a Forum , a city will retrieve a coastal zone . Ciudad recobrarà una zona de costal después Foro . Città ricuperarà une zona costiera dopo Forum . In the second scenario , there is a UNL graph associated with the modified segment . In order to share the revisions across languages , we should reflect them on the UNL graph , e.g . • add `` . @ def '' on the nodes `` city '' & `` Forum '' . • replace `` retrieve '' by `` recover '' and add `` . @ complete '' on the node containing it . It is not possible in principle to deduce the modification on the graph from a modification on the text . For example , replacing `` un '' ( `` a '' ) by `` le '' ( `` the '' ) does not entail that the following noun is determined ( . @ def ) , because it can also be generic ( `` il aime la montagne '' = `` he likes mountains '' ) . Hence , the technique envisaged is that : • revision is not done by modifying directly the text , but by using a menu system , • the menu items have a `` language side '' and a hidden `` UNL side '' , • when a menu item is chosen , only the graph is transformed , and the action to be done on the text is stored and shown next to its focus . • at any time , the new graph may be sent to the L0 deconverter and the result shown . If is is satisfactory , that shows that errors were due to the graph and not to the deconverter , and the graph may be sent to deconverters in other languages . Versions in some other languages known by the user may be displayed , so that improvement sharing is visible and encouraging . New versions will be added with appropriate tags and attributes in the multilingual document in UNLxml format , or in a DBMS , so that nothing is lost , and cooperative working on a document is feasible . For the above method to work , the text has to be preprocessed , at least by computing morphosyntactic classes ( POS & actualization attributes ) to avoid many spurious menus , segmenting , and lemmatizing . Because we want our technique to be widely applicable , this preprocessing should be such that it can be performed by large coverage tools freely available for many languages . That is the case for morphosyntactic analyzers ( MSA ) , but not yet for full or even shallow parsers . We also propose that the revision interface should allow access not only to the texts , but to editable representations of the UNL graph , of the result of the MSA , and of any other available structure such as a tree derived from the UNL graph . For users not wanting to see anything else than text , the previous scenario will always be usable . But there are good reasons to `` open the black box '' : ( 1 ) the UNL Spanish group has successfully experimented with an interface for interactive UNL graph creation using a MSA and a graph editor showing the UNL graph in a `` localized '' way ( symbols & lexemes appear in Spanish ) , ( 2 ) it is sometimes much quicker to change something on another representation than on a text : for example , to merge two nodes in order to change `` Mary likes Mary 's daughter '' into `` Mary likes her daughter '' , ( 3 ) it may even be necessary , if the correspondence is faulty and can not be improved because the text is very far from any reasonable deconversion obtainable from the graph , ( 4 ) user interface technology has made much progress , and offers tools to build user-friendly direct manipulation environments , ( 5 ) last but not least , the younger generation manipulates complex interfaces very naturally and expertly , far better than its elders ! We identify 4 common types of errors in the corpus we have analysed so far : ( 1 ) graphs containing false information : wrong attachment , wrong choice of UW , wrong attribute , wrong semantic relation… ( 2 ) graphs with missing information , as above , ( 3 ) absence of text because the UNL graph is formally incorrect ( due to some wrong human manipulation , some bug in a deconverter… ) : missing parenthesis , missing entry node in a scope , disconnected graph… , ( 4 ) deconversion errors . Our method can be used for correcting the first 2 types of errors only . If a graph is formally incorrect , it may displayable or not . In the first case , it should be possible to manipulate and correct it graphically , e.g . by connecting 2 disconnected parts or choosing an entry node . In the second case , it is necessary to work on a textual representation . If errors come from the deconverter , the user may still correct the text by hand ( last zone ) . ↔graph correspondence The correspondence between a text and a UNL graph may be decomposed into less complex liaisons , which are often not simple links , even between words and nodes . We found the following types in this case . We have already begun to break down the correspondence in 2 parts : text ↔ MS-structure ↔ UNL graph . The MS structure may always be embedded in a loop-free graph with information on the nodes ( lattice ) or on the arcs ( charts ) , so that the first part of the correspondence is made of liaisons between substrings of the text ( not necessarily always connex ) and elements ( nodes or arcs ) on the trajectory corresponding to the preferred interpretation ( in case of ambiguity ) . It is perhaps possible to compute a direct correspondence between the MS lattice and the UNL graph , but it is not clear how to represent the liaisons between phrases and subgraphs . For that purpose , a tree structure is far better . Because there is no available large-scale and free syntacticosemantic analyzer for the vast majority of languages , we can not use even a tree produced by a shallow parser . But it is possible to associate a `` standard UNL-tree '' to any UNL graph by a reversible algorithmic transformation [ 3 , 4 , 10 ] : start at the outer entry node , and traverse the graph and its scopes ( subgraphs ) recursively , thereby creating auxiliary nodes for scopes , `` inverse '' semantic relations for arcs in the `` wrong '' direction , and coindexing symbols to represent reentrancy without duplication . We can also take advantage of having one more structure by enriching it with lexical units of L0 . Now the correspondence is broken into 3 parts : • text ↔ MS-L0 ( a lattice or a chart ) , • MS-L0 ↔ UNL-tree+L0 ( an unordered abstract quasi-dependency tree ) , and • UNL-tree+L0 ↔ UNL-graph ( liaisons may be produced by modifying the standard reversible graph2tree transformation ) . Another advantage of introducing this tree structure is that the correspondences between strings and abstract trees have been much studied [ 5 , 15 , 16 ] . They can be encoded within the trees by 2 attributes expressing what a node covers lexically ( SNODE ) and as root of a subtree ( STREE ) . We have implemented a web site called SWIIVRE-UNL 2 Let us outline the method ( currently under implementation ) to compute a `` best '' correspondence . We start with an MS-L0 lattice linked to the text and a UNL-tree produced in a standard way and linked to the UNL graph . The goal is to establish liaisons between the lattice and the tree , and to order the tree so that it is maximally aligned with the lattice , hence with the text . Suppose we have only an L0-English dictionary . First , we enrich the lattice with English lemmas and the UNL-tree with lemmas of L0 , producing MS-L0+EN and UNL-tree+L0 . Then , we establish links between nodes of the lattice and of the tree having lemmas in common ( in L0 or in English ) , and compute a score for each trajectory in the lattice . The best trajectory is chosen . The next phase consists in aligning the tree with that trajectory , using `` sure '' links as the point of departure , and constraints on the STREE and SNODE liaisons : if there are crossing links , which is possible if two words in the text have similar meanings , preference is given to the link maximizing the proximity in the tree and in the string . Then , liaisons of other types are established : lexemes with semantic relations , lexemes with attributes , and MS attributes with attributes . Sending feedback automatically to developers is already done in some MT systems , notably in Taiwan ( EKS ) and at PAHO [ 14 ] , but should be much more used than it is . The idea of coedition is also not new : UPM in Madrid uses it to create UNL graphs , Y. Lepage at ATR and Tang E. K. at USM ( Penang ) have developed editors of string-tree correspondences , Watanabe at IBM-Japan has a very nice interface to edit from a text its underlying dependency structure , the MULTIMETEO system [ 8 ] is in effect a coedition system for weather forecasts and their underlying semantic structure , in 6 languages , and there is a project at Xerox working on multilingual generation and free text normalization in restricted domains and typologies ( pharmaceutical notices ) . In our case , by contrast , coedition is to happen at the consumer side , not ( like at UPM ) at the producer side , and there is no specific domain or typology . The idea to derive an abstract semantic tree from an IL representation using alignment techniques and not a rule system embedded in a generator seems also to be new . Coedition of a natural language text and its representation in some interlingual form seems the best way to share text revision across languages . UNL graphs seem to be the best candidates in this context . We have described an approach where , in the simplest sharing scenario , naive users interact directly with the text in their language ( L0 ) , and indirectly with the associated graph . It should also be possible to view and directly manipulate the given UNL graph , a lattice or chart produced by some available free morphosyntactic analyzer , and an abstract tree produced not by analysis , but by a standard transformation from the UNL graph , followed by lexical enrichment in L0 , and alignment with the text . When completed , our implementation will make it possible to share revision across languages . We will then have progressed towards merging pivot MT , interactive MT , and multilingual text authoring . http : //www-clips.imag.fr/geta/User/wang-ju.tsai/ welcome.html 